{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ec800a",
   "metadata": {},
   "source": [
    "# Using an already existing model that has been trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a83272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyteomics\n",
    "import pandas as pd\n",
    "import time\n",
    "from pyteomics import mzml\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import numpy as np\n",
    "from pandas_path import path\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import make_scorer, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import joblib\n",
    "\n",
    "from datetime import datetime\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "RANDOM_SEED = 42  # For reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be985c73",
   "metadata": {},
   "source": [
    "# Prediction features should already be converted to excel format, excel files should then be transfered to 'pred_features' that is inside 'prediction data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3eaf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the 'predictions_data_folder'\n",
    "predictions_data_folder = os.path.join(os.getcwd(), 'predictions data')\n",
    "predictions_features_folder = os.path.join(predictions_data_folder, 'pred_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353348a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all_labels for the format of report\n",
    "data_directory = os.path.join(os.getcwd(), 'data')\n",
    "file_path = os.path.join(data_directory, 'all_labels.csv')\n",
    "all_labels = pd.read_csv(file_path)\n",
    "\n",
    "# List the files in the 'predictions_data_folder' with '.xlsx' extension\n",
    "prediction_data_files = [file for file in os.listdir(predictions_features_folder) if file.endswith('.xlsx')]\n",
    "\n",
    "# Create dict with test sample IDs and paths\n",
    "pred_dict = {pred_name[:-5]: \"pred_features\\\\\" + pred_name for pred_name in predictions_features_folder} \n",
    "\n",
    "# Remove \".xlsx\" from the elements in prediction_data_files\n",
    "prediction_data_files = [file.replace('.xlsx', '') for file in prediction_data_files]\n",
    "\n",
    "# Create the report_format DataFrame with the same columns as all_labels and the file names as indexes\n",
    "report_format = pd.DataFrame(columns=all_labels.columns[1:], index=prediction_data_files)\n",
    "\n",
    "# Set the index header\n",
    "report_format.index.name = \"sample id\"\n",
    "\n",
    "# Define the file paths\n",
    "report_format_path = os.path.join(predictions_data_folder, 'report_format.csv')\n",
    "\n",
    "# Save test_labels in the data_directory folder\n",
    "report_format.to_csv(report_format_path)\n",
    "\n",
    "# Print the report_format DataFrame with the file names as indexes\n",
    "print(report_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56e6741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import submission format\n",
    "submission_template_df = pd.read_csv(os.path.join(predictions_data_folder, \"report_format.csv\"), index_col=\"sample id\")\n",
    "                                     \n",
    "compounds_order = submission_template_df.columns\n",
    "sample_order = submission_template_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a143af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series of time bins\n",
    "timerange = pd.interval_range(start=0, end=35, freq=0.25)\n",
    "timerange\n",
    "\n",
    "# Make dataframe with rows that are combinations of all temperature bins and all m/z values\n",
    "allcombs = list(itertools.product(timerange, [*range(1, 301)]))\n",
    "\n",
    "allcombs_df = pd.DataFrame(allcombs, columns=[\"time bin\", \"rounded m/z\"])\n",
    "print(allcombs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1356a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_per_timebin(df):\n",
    "\n",
    "    \"\"\"\n",
    "    Transforms dataset to take the preprocessed max abundance for each\n",
    "    time range for each m/z value\n",
    "\n",
    "    Args:\n",
    "        df: dataframe to transform\n",
    "\n",
    "    Returns:\n",
    "        transformed dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Bin times\n",
    "    df[\"time bin\"] = pd.cut(df[\"scan time\"], bins=timerange)\n",
    "\n",
    "    # Combine with a list of all time bin-m/z value combinations\n",
    "    df = pd.merge(allcombs_df, df, on=[\"time bin\", \"rounded m/z\"], how=\"left\")\n",
    "\n",
    "    # Aggregate to time bin level to find max\n",
    "    df = df.groupby([\"time bin\", \"rounded m/z\"]).max(\"normalised intensity\").reset_index()\n",
    "\n",
    "    # Fill in 0 for intensity values without information\n",
    "    df = df.replace(np.nan, 0)\n",
    "\n",
    "    # Reshape so each row is a single sample\n",
    "    df = df.pivot_table(\n",
    "        columns=[\"rounded m/z\", \"time bin\"], values=[\"normalised intensity\"]\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5922f07b",
   "metadata": {},
   "source": [
    "# Refers to model folder containing all previously trained models for each compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8975a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models folder path\n",
    "MODELS_PATH = os.path.join(os.getcwd(), 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_sample(sample_id, models_folder_path):\n",
    "\n",
    "    # Import sample\n",
    "    temp_sample = pd.read_excel(os.path.join(predictions_data_folder, pred_dict[sample_id]))\n",
    "\n",
    "    # Feature engineering on sample\n",
    "    temp_sample = int_per_timebin(temp_sample)\n",
    "\n",
    "    # Generate predictions for each class\n",
    "    temp_sample_preds_dict = {}\n",
    "\n",
    "    for compound in compounds_order:\n",
    "        # Load the trained model from the MODELS_PATH folder\n",
    "        model_filename = os.path.join(models_folder_path, f\"logreg_model_{compound}.joblib\")\n",
    "        clf = joblib.load(model_filename)\n",
    "\n",
    "        # Make predictions for the sample using the loaded model\n",
    "        temp_sample_preds_dict[compound] = clf.predict_proba(temp_sample.values)[:, 1][0]\n",
    "\n",
    "    return temp_sample_preds_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f5bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to store logreg submissions in\n",
    "final_submission_df = pd.DataFrame(\n",
    "    [\n",
    "        predict_for_sample(sample_id, MODELS_PATH)\n",
    "        for sample_id in tqdm(sample_order)\n",
    "    ],\n",
    "    index=sample_order,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50765706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that columns and rows are the same between final submission and submission format\n",
    "assert final_submission_df.index.equals(submission_template_df.index)\n",
    "assert final_submission_df.columns.equals(submission_template_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871775ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming final_submission_df is the DataFrame you want to save\n",
    "current_datetime = datetime.now().strftime(\"%d%m%Y_%H%M\")  # Get current date and time as a string\n",
    "file_name = f\"report_{current_datetime}.csv\"  # Create the file name with current date and time\n",
    "\n",
    "final_submission_df.to_csv(file_name, index=False)\n",
    "\n",
    "# Load the workbook\n",
    "wb = load_workbook(file_name)\n",
    "\n",
    "# Get the first sheet (assuming there is only one sheet in the Excel file)\n",
    "sheet = wb.active\n",
    "\n",
    "# Autofit column widths for all columns\n",
    "for column_cells in sheet.columns:\n",
    "    length = max(len(str(cell.value)) for cell in column_cells)\n",
    "    adjusted_width = length # Add a little padding and adjust to Excel's internal width units\n",
    "    sheet.column_dimensions[column_cells[0].column_letter].width = adjusted_width\n",
    "\n",
    "# Save the updated workbook\n",
    "wb.save(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca8dbbf",
   "metadata": {},
   "source": [
    "# End of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed15d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
